{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - CNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set for this exercise contains rendered images of 16 different types of Lego bricks. This is an image classification task: build a model that can correctly identify lego bricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the LEGO folder on your computer (as part of the downloaded files). Use the **train** folder and build a model to predict the **category** of each image. Then, validate your model on the images in the **valid** folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6379 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "#Image Data Generator manipulates and \"augments\" images\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "\n",
    "# Directory Iterator reads images from a directory\n",
    "\n",
    "train_data = DirectoryIterator(\n",
    "    directory=\"LEGO/train\",\n",
    "    image_data_generator = train_datagen,\n",
    "    target_size=(16, 16),                    ###### ENTER values for XXX ########\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=100,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1555 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "valid_data = DirectoryIterator(\n",
    "    directory=\"LEGO/valid\",\n",
    "    image_data_generator = valid_datagen,\n",
    "    target_size=(16, 16),                     ###### ENTER values for XXX ########\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=100,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your model \n",
    "\n",
    "**Be careful with the output layer: number of neurons must match the number of categories to predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 16, 16, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 8, 8, 16)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8, 8, 16)          0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 3, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3, 3, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               36992     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,144\n",
      "Trainable params: 44,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', \n",
    "                 input_shape=(16,16,3)))\n",
    "\n",
    "#model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "#model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "#### FIXED!!!!!!!\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# initiate adam optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "64/64 [==============================] - 8s 112ms/step - loss: 2.1638 - accuracy: 0.2366 - val_loss: 1.3163 - val_accuracy: 0.5299\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 7s 106ms/step - loss: 1.4236 - accuracy: 0.4421 - val_loss: 1.0047 - val_accuracy: 0.6135\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 7s 106ms/step - loss: 1.2629 - accuracy: 0.5089 - val_loss: 0.9239 - val_accuracy: 0.6437\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 7s 106ms/step - loss: 1.2060 - accuracy: 0.5297 - val_loss: 0.8505 - val_accuracy: 0.6450\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 7s 113ms/step - loss: 1.1408 - accuracy: 0.5510 - val_loss: 0.8313 - val_accuracy: 0.6656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29ae538d190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_data,\n",
    "        epochs=5,\n",
    "        validation_data=valid_data,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT A SINGLE IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29aec30d430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "img = load_img(\"LEGO/valid/2357 Brick corner 1x2x2/201706171206-0312.png\",\n",
    "               color_mode='rgb',\n",
    "               target_size=(16,16)\n",
    "              )\n",
    "\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.0695222e-08, 7.1363331e-08, 5.9604788e-01, 3.7660964e-02,\n",
       "        3.4304127e-02, 6.1822036e-12, 3.2957378e-01, 5.0361990e-09,\n",
       "        8.6130851e-12, 1.2551021e-03, 4.7125926e-08, 3.1374358e-13,\n",
       "        2.1813102e-14, 7.2857417e-14, 2.1717674e-09, 1.1579409e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the image to array\n",
    "single_image = img_to_array(img)\n",
    "\n",
    "#Also divide the image values by 255 to normalize\n",
    "img_rank = np.expand_dims(single_image/255, axis=0)\n",
    "\n",
    "model.predict(img_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.6 , 0.04, 0.03, 0.  , 0.33, 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(img_rank),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can predict the class directly using the following function:\n",
    "\n",
    "np.argmax(model.predict(img_rank), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11214 Bush 3M friction with Cross axle': 0,\n",
       " '18651 Cross Axle 2M with Snap friction': 1,\n",
       " '2357 Brick corner 1x2x2': 2,\n",
       " '3003 Brick 2x2': 3,\n",
       " '3004 Brick 1x2': 4,\n",
       " '3005 Brick 1x1': 5,\n",
       " '3022 Plate 2x2': 6,\n",
       " '3023 Plate 1x2': 7,\n",
       " '3024 Plate 1x1': 8,\n",
       " '3040 Roof Tile 1x2x45deg': 9,\n",
       " '3069 Flat Tile 1x2': 10,\n",
       " '32123 half Bush': 11,\n",
       " '3673 Peg 2M': 12,\n",
       " '3713 Bush for Cross Axle': 13,\n",
       " '3794 Plate 1X2 with 1 Knob': 14,\n",
       " '6632 Technic Lever 3M': 15}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can retrieve the class labels from the train_generator:\n",
    "\n",
    "label_map = (train_data.class_indices)\n",
    "\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2357 Brick corner 1x2x2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can retrieve the class label of the prediction:\n",
    "\n",
    "list(label_map.keys())[np.argmax(model.predict(img_rank4), axis=-1)[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
